<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<title>Onoclea Bits - A Tasty Bite of IT</title>
	<link href="http://en.onoclea.com/atom.xml" rel="self"/>
	<link href="http://en.onoclea.com/"/>
	<updated>2013-02-11T20:22:21+01:00</updated>
	<id>http://en.onoclea.com/</id>
	<author>
		<name>Pawel Jan Sawicki</name>
		<email>pawel.sawicki@onoclea.com</email>
	</author>
	
	<entry>
		<title>Forwarding (routing) DLNA/UPnP broadcasts on Linux (virtual setup using KVM).</title>
		<link href="http://en.onoclea.com/bits/linux-kvm-dlna-upnp-smcroute.html"/>
		<updated>2013-01-10T00:00:00+01:00</updated>
		<id>http://en.onoclea.com/bits/linux-kvm-dlna-upnp-smcroute</id>
		<content type="html">&lt;p&gt;One of the recent updates in my home infrastructure was to convert from VMware to Linux KVM in terms of the virtualisation platform. Everything went smoothly, virtual machines have been successfuly converted. There was one tiny problem however - my UPnP media server, running PS3 Media Server, stopped to be visible from both the Playstation3 and the AVR (H/K AVR-270). It took me a day of troubleshooting but finally everything is working once again.&lt;/p&gt;

&lt;h2 id='symptoms'&gt;Symptoms&lt;/h2&gt;

&lt;p&gt;From the &amp;#8220;business&amp;#8221; side effects were quite obvious. Neither the PS3 nor the H/K AVR were able to see the media server. Technically, after a bit of digging, it turned out that the multicast discovery sent from the virtual machine hasn&amp;#8217;t been forwarded/routed by the virtual hypervisor. The VM host saw the multicast communication sent to 239.255.255.250, port 1900 but it didn&amp;#8217;t put it through.&lt;/p&gt;

&lt;h2 id='fix'&gt;Fix&lt;/h2&gt;

&lt;p&gt;The fix turned out to be quite simple yet it took a lot of time to figure out - &lt;a href='smcroute'&gt;https://github.com/troglobit/smcroute&lt;/a&gt; or &amp;#8220;simple multicast router&amp;#8221; came to the rescue.&lt;/p&gt;

&lt;h3 id='vm_hypervisor'&gt;VM hypervisor&lt;/h3&gt;

&lt;p&gt;The VM hypervisor configuration (br0 is the bridge that all virtual machines are connected to):&lt;/p&gt;

&lt;p&gt;&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='o'&gt;[&lt;/span&gt;root@blackbox ~&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='c'&gt;# smcroute -j br0 239.255.255.250&lt;/span&gt;
&lt;span class='o'&gt;[&lt;/span&gt;root@blackbox ~&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='c'&gt;# smcroute -a br0 0.0.0.0 239.255.255.250 br0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;Moreover, one has to disable the multicast snooping functionality of the Linux router by setting the appropriate flag (it&amp;#8217;s not yet, as of Feb 2013, available via systcl):&lt;/p&gt;

&lt;p&gt;&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='o'&gt;[&lt;/span&gt;root@blackbox ~&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='c'&gt;# echo 0 &amp;gt; /sys/devices/virtual/net/br0/bridge/multicast_snooping&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;h3 id='media_server'&gt;media server&lt;/h3&gt;

&lt;p&gt;The media server configuration:&lt;/p&gt;

&lt;p&gt;&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='o'&gt;[&lt;/span&gt;root@media ~&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='c'&gt;# smcroute -j eth0 239.255.255.250&lt;/span&gt;
&lt;span class='o'&gt;[&lt;/span&gt;root@media ~&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='c'&gt;# smcroute -a eth0 0.0.0.0 239.255.255.250 eth0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;And that&amp;#8217;s it - now both the game console and the AVR could see the UPnP server.&lt;/p&gt;</content>
	</entry>
	
	<entry>
		<title>How to make the HP MicroServer Remote Access Card to work via IPMI (ipmitool) on ArchLinux (or any other Linux distro in general)?</title>
		<link href="http://en.onoclea.com/bits/hp-microserver-remote-access-card-ipmi-on-linux.html"/>
		<updated>2012-11-02T00:00:00+01:00</updated>
		<id>http://en.onoclea.com/bits/hp-microserver-remote-access-card-ipmi-on-linux</id>
		<content type="html">&lt;p&gt;Couple of days back I wanted to access the HP MicroServer Remote Access Card via the IPMI (ipmitool) interface. The reason was quite simple - I locked myself out from the web interface by setting a password that included &amp;#8220;special&amp;#8221; (in my case the &amp;#8221;&amp;amp;&amp;#8221;) characters. UI allowed me to change the password, but then refused to let me in&amp;#8230; Getting back to the point.&lt;/p&gt;

&lt;p&gt;After probing the respective modules (&lt;code&gt;ipmi_devintf&lt;/code&gt; &amp;amp; &lt;code&gt;ipmi_si&lt;/code&gt;) nothing worked.&lt;/p&gt;

&lt;p&gt;&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='o'&gt;[&lt;/span&gt;root@host&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='c'&gt;# ipmitool chassis status&lt;/span&gt;
Could not open device at /dev/ipmi0 or /dev/ipmi/0 or /dev/ipmidev/0: No such file or directory
Error sending Chassis Status &lt;span class='nb'&gt;command&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;It turned out to be a problem with the default internall communication port, that was not picked up correctly. The manual (see the link below) states it clearly - quote from the docs (page no. 5):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The default system base address for the I/O mapped KCS Interface is 0xCA2 (&amp;#8230;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So, to make things right, one must pass the correct &lt;code&gt;ports&lt;/code&gt; parameter to the &lt;code&gt;ipmi_si&lt;/code&gt; module while probing:&lt;/p&gt;

&lt;p&gt;&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='o'&gt;[&lt;/span&gt;root@host&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='c'&gt;# modprobe ipmi_devinf&lt;/span&gt;
&lt;span class='o'&gt;[&lt;/span&gt;root@host&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='c'&gt;# modprobe ipmi_si type=kcs ports=0xca2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;Now the kernel recognizes the card without any problems:&lt;/p&gt;

&lt;p&gt;&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='o'&gt;[&lt;/span&gt;root@host&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='c'&gt;# dmesg&lt;/span&gt;
&lt;span class='o'&gt;[&lt;/span&gt;32559.752311&lt;span class='o'&gt;]&lt;/span&gt; IPMI System Interface driver.
&lt;span class='o'&gt;[&lt;/span&gt;32559.752321&lt;span class='o'&gt;]&lt;/span&gt; ipmi_si: probing via hardcoded address
&lt;span class='o'&gt;[&lt;/span&gt;32559.752326&lt;span class='o'&gt;]&lt;/span&gt; ipmi_si: Adding hardcoded-specified kcs state machine
&lt;span class='o'&gt;[&lt;/span&gt;32559.752336&lt;span class='o'&gt;]&lt;/span&gt; ipmi_si: Trying hardcoded-specified kcs state machine at i/o address 0xca2, slave address 0x0, irq 0
&lt;span class='o'&gt;[&lt;/span&gt;32560.211697&lt;span class='o'&gt;]&lt;/span&gt; ipmi_si ipmi_si.0: Found new BMC &lt;span class='o'&gt;(&lt;/span&gt;man_id: 0x000001, prod_id: 0x3431, dev_id: 0x20&lt;span class='o'&gt;)&lt;/span&gt;
&lt;span class='o'&gt;[&lt;/span&gt;32560.211973&lt;span class='o'&gt;]&lt;/span&gt; ipmi_si ipmi_si.0: IPMI kcs interface initialized
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;More importantly, &lt;code&gt;ipmitool&lt;/code&gt; just works:&lt;/p&gt;

&lt;p&gt;&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='o'&gt;[&lt;/span&gt;root@host&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='c'&gt;# ipmitool chassis status&lt;/span&gt;
System Power         : on
Power Overload       : &lt;span class='nb'&gt;false&lt;/span&gt;
Power Interlock      : inactive
Main Power Fault     : &lt;span class='nb'&gt;false&lt;/span&gt;
Power Control Fault  : &lt;span class='nb'&gt;false&lt;/span&gt;
Power Restore Policy : always-off
Last Power Event     : &lt;span class='nb'&gt;command&lt;/span&gt;
Chassis Intrusion    : inactive
Front-Panel Lockout  : inactive
Drive Fault          : &lt;span class='nb'&gt;false&lt;/span&gt;
Cooling/Fan Fault    : &lt;span class='nb'&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;h2 id='archlinux_specific_settings'&gt;ArchLinux specific settings&lt;/h2&gt;

&lt;p&gt;In ArchLinux, in order to set those options permanently, you need to create two files, in order to&amp;#8230;&lt;/p&gt;

&lt;h3 id='load_the_necessary_modules_at_boot'&gt;&amp;#8230;load the necessary modules at boot&lt;/h3&gt;

&lt;p&gt;Create a file in &lt;code&gt;/etc/modules-load.d&lt;/code&gt;, e.g. &lt;code&gt;ipmi.conf&lt;/code&gt;:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='c'&gt;# cat /etc/modules-load.d/ipmi.conf &lt;/span&gt;
ipmi_devintf
ipmi_si
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now, on boot, ArchLinux will load those two modules automatically.&lt;/p&gt;

&lt;h3 id='set_the_respective_options_while_loading__module'&gt;&amp;#8230;set the respective options while loading &lt;code&gt;ipmi_si&lt;/code&gt; module&lt;/h3&gt;

&lt;p&gt;Create a file named &lt;code&gt;ipmi_si&lt;/code&gt; in &lt;code&gt;/etc/modprobe.d&lt;/code&gt;:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='c'&gt;# cat /etc/modprobe.d/ipmi_si.conf &lt;/span&gt;
options ipmi_si &lt;span class='nb'&gt;type&lt;/span&gt;&lt;span class='o'&gt;=&lt;/span&gt;kcs &lt;span class='nv'&gt;ports&lt;/span&gt;&lt;span class='o'&gt;=&lt;/span&gt;0xca2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will make sure that the &lt;code&gt;ipmi_si&lt;/code&gt; module receives the correct options upon loading.&lt;/p&gt;

&lt;h2 id='useful_links'&gt;Useful links&lt;/h2&gt;

&lt;p&gt;While applying the RTFM method, the &lt;em&gt;M&lt;/em&gt; part is sometimes quite handy:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href='http://h10030.www1.hp.com/ctg/Manual/c02948881.pdf' title='HP MicroServer Remote Access Card manual'&gt;http://h10032.www1.hp.com/ctg/Manual/c02948881.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>
	</entry>
	
	<entry>
		<title>csync2 - When all you need is a multi-way synchronization tool</title>
		<link href="http://en.onoclea.com/bits/csync2-multi-way-sync.html"/>
		<updated>2011-07-08T00:00:00+02:00</updated>
		<id>http://en.onoclea.com/bits/csync2-multi-way-sync</id>
		<content type="html">&lt;p&gt;Scaling a system horizontally usually requires sharing some data between your worker nodes. If your architecture justifies a database server (be it either SQL or NoSQL) then that&amp;#8217;s usually a quite trivial task (as long as you assure that your database layer scales, which is another kind of a problem). However, if your requirements are different - like e.g. POSIX compliancy - then you need to look for someting else.&lt;/p&gt;

&lt;p&gt;(Un)fortunately, setting up &lt;a href='http://www.drbd.org/'&gt;DRBD&lt;/a&gt; and &lt;a href='http://oss.oracle.com/projects/ocfs2/'&gt;OCFS2&lt;/a&gt; isn&amp;#8217;t that easy. It&amp;#8217;s doable, of course, and works great if done right. Unfortunately, being a complex system makes it susceptible to errors that do occur (by Murphy&amp;#8217;s law and by statistics) more often than in some less complicated setups.&lt;/p&gt;

&lt;p&gt;Luckily, if you need a multi-way synchronization tool and you can deal with some limitations, then you should definitely try &lt;a href='http://oss.linbit.com/csync2/'&gt;csync2&lt;/a&gt; - a tool developed by the authors of &lt;a href='http://www.drbd.org'&gt;DRBD&lt;/a&gt;, that can sometimes turn quite handy.&lt;/p&gt;

&lt;h2 id='what_is_csync2'&gt;What is csync2?&lt;/h2&gt;

&lt;p&gt;Authors describe &lt;a href='http://oss.linbit.com/csync2/'&gt;csync2&lt;/a&gt; as a:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Csync2 is a cluster synchronization tool. It can be used to keep files on multiple hosts in a cluster in sync. Csync2 can handle complex setups with much more than just 2 hosts, handle file deletions and can detect conflicts.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;So how can it be helpful? I&amp;#8217;ll describe one of the use cases I came across recently.&lt;/p&gt;

&lt;h2 id='serving_web_assets_static_files_with_multiple_http_server_nodes_nginx'&gt;Serving web assets (static files) with multiple http server nodes (nginx)&lt;/h2&gt;

&lt;p&gt;The system I worked with started as a simple and durable setup. The application layer consisted of two application nodes, working in a hot-standby mode. The initial requirements set to have HA (high availability), not a LB (load balance). So whenever the master node failed (or was set to fail), the slave took over (with some virtual IP magic under the hood). This means, that only one node was active at a time. This was fine until a single machine couldn&amp;#8217;t handle the load. The system did have a database server, but both application nodes had to have an access to a shared storage - a place where some static files were kept.&lt;/p&gt;

&lt;h2 id='requirements'&gt;Requirements&lt;/h2&gt;

&lt;p&gt;First of all I ruled out solutions that required extra nodes (a business requirement). So a pair of new NFS servers was not an option. Moreover, the design had to scale for more than two nodes. This made rsync and similar &amp;#8220;one way sync&amp;#8221; tools inaplicable as well.&lt;/p&gt;

&lt;h2 id='drbd__too_powerful'&gt;DRBD - too powerful&lt;/h2&gt;

&lt;p&gt;After some research two approaches surfaced.&lt;/p&gt;

&lt;p&gt;One was to use a full-blown replicated filesystem (OCFS2) with a shared block storage beneath (DRBD). It was a stripped version of the NFS server idea, but turned to be cumbersome to scale and, at least initially (&lt;em&gt;&amp;#8220;The First Rule of Program Optimization: Don&amp;#8217;t do it. The Second Rule of Program Optimization (for experts only!): Don&amp;#8217;t do it yet.&amp;#8221;&lt;/em&gt; - quote by Michael A. Jackson) it was like using cannon to kill a fly.&lt;/p&gt;

&lt;h2 id='csync2'&gt;csync2&lt;/h2&gt;

&lt;p&gt;Then I&amp;#8217;ve tried to setup csync2 - a tool I came across while doing some research about DRBD some time ago. After about 30 minutes the system was up and running. The setup is very simple - all you need is a single configuration file:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;group app &lt;span class='o'&gt;{&lt;/span&gt;
 host app0.example.com app1.example.com app2.example.com;

 key /etc/csync2.key-app;

 include /vol/0/app/shared;
 include /vol/0/app/spool;

 backup-directory /vol/csync2/backup;
 backup-generations 3;

 auto none;
&lt;span class='o'&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And that&amp;#8217;s it - this helps you to have &lt;code&gt;/vol/0/app/shared&lt;/code&gt; and &lt;code&gt;/vol/0/app/spool&lt;/code&gt; synchronized between all the nodes. If a files is added, modified or deleted then the change is automatically propagated to other nodes.&lt;/p&gt;

&lt;h2 id='batch_mode_of_operation'&gt;Batch mode of operation&lt;/h2&gt;

&lt;p&gt;There&amp;#8217;s one catch, however. Csync2 works in batch mode, so you don&amp;#8217;t get an on-line synchronization. Running csync2 from cron every minute (or in a loop) doesn&amp;#8217;t solve that either. Moreover, if you deal with hundreds of thousands of files, then it takes some time to scan all files for potential differences.&lt;/p&gt;

&lt;p&gt;However, if you can modify you application to trigger csync2, this can easily be solved by the following wrapper script.&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='c'&gt;#!/bin/bash&lt;/span&gt;

/usr/sbin/csync2 -v -m &lt;span class='nv'&gt;$@&lt;/span&gt; 2&amp;gt;&amp;amp;1 | /usr/bin/logger -t csync2
/usr/sbin/csync2 -v -u 2&amp;gt;&amp;amp;1 | /usr/bin/logger -t csync2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;First it sets its argument as &amp;#8220;dirty&amp;#8221; (so pending synchronization). Then it updates all elements with the &amp;#8220;dirty&amp;#8221; flag set. It&amp;#8217;s fast as csync2 doesn&amp;#8217;t compare all the files and checks only the one that have been pointed out.&lt;/p&gt;

&lt;p&gt;The logger part gives you an audit log of all the things that happened - just to check if everything is OK.&lt;/p&gt;

&lt;h2 id='problems'&gt;Problems&lt;/h2&gt;

&lt;p&gt;There was one problem I had to deal with. After generating the certificates the csync2 nodes couldn&amp;#8217;t connect. It turned to be a known bug:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href='http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=501289'&gt;http://bugs.debian.org/cgi-bin/bugreport.cgi?bug=501289&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;a href='http://archives.free.net.ph/message/20080811.081952.de6b9f3e.ja.html'&gt;http://archives.free.net.ph/message/20080811.081952.de6b9f3e.ja.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Copying certificate and key files solved the problem.&lt;/p&gt;</content>
	</entry>
	
	<entry>
		<title>How to host your site on Dreamhost (or any shared hosting site) with an external DNS server</title>
		<link href="http://en.onoclea.com/bits/external-dns-and-shared-hosting-like-dreamhost.html"/>
		<updated>2011-01-21T00:00:00+01:00</updated>
		<id>http://en.onoclea.com/bits/external-dns-and-shared-hosting-like-dreamhost</id>
		<content type="html">&lt;p&gt;Dreamhost is one of the best shared-hosting sites I&amp;#8217;ve came across. It has its ups and downs, but all in all it&amp;#8217;s very useful in many situations. In my particular case I use it to host some of my family&amp;#8217;s sites and files. I could do it on my own, but I prefer to pay $10 a month and sleep safe and sound :)&lt;/p&gt;

&lt;h2 id='the_problem'&gt;The problem&lt;/h2&gt;

&lt;p&gt;There&amp;#8217;s one problem, however. I don&amp;#8217;t use &lt;a href='http://www.dreamhost.com/r.cgi?215063'&gt;Dreamhost&lt;/a&gt; to host my domains. So the question is - how do you reliably setup a DNS record (e.g. go.pjs.name used in the example below) to point it to a Dreamhosts&amp;#8217; IP address, which can change? The solution is quite straightforward and easy to implement. What you need to to is to point your subdomain&amp;#8217;s (e.g. go.pjs.name) domain name servers (it&amp;#8217;s legit and nothing out of ordinary) to the &lt;a href='http://www.dreamhost.com/r.cgi?215063'&gt;Dreamhost&lt;/a&gt; defined ones (&lt;code&gt;ns1.dreamhost.com&lt;/code&gt;, &lt;code&gt;ns2.dreamhost.com&lt;/code&gt;, &lt;code&gt;ns3.dreamhost.com&lt;/code&gt;). This way you:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;retain full control over your domain&lt;/li&gt;

&lt;li&gt;delegate authority for the subdomain (the one hosted on Dreamhost) so whenever somebody at Dreamhost decides to change the IP address of the server that keeps your data, you are completely safe and don&amp;#8217;t have to change anything&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;BTW - this technique is universal and can be applied to any shared hosting site, or any similar situation.&lt;/p&gt;

&lt;h2 id='example'&gt;Example&lt;/h2&gt;

&lt;p&gt;See the following example as it may shed some light on the solution, since the particular implementation depends on where you keep your domain.&lt;/p&gt;

&lt;h3 id='my_domain__'&gt;My domain - &lt;code&gt;pjs.name&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;I own a &lt;code&gt;pjs.name&lt;/code&gt; domain and host its DNS servers externally:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='nv'&gt;$ &lt;/span&gt;dig -t ns pjs.name

;; QUESTION SECTION:
;pjs.name.                      IN      NS

;; ANSWER SECTION:
pjs.name.               86400   IN      NS      ns2.onoclea.net.
pjs.name.               86400   IN      NS      ns1.onoclea.net.
pjs.name.               86400   IN      NS      ns3.onoclea.net.
pjs.name.               86400   IN      NS      ns5.onoclea.net.
pjs.name.               86400   IN      NS      ns6.onoclea.net.
pjs.name.               86400   IN      NS      ns4.onoclea.net.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;OK, so what about the site I wish to keep at my shared hosting site?&lt;/p&gt;

&lt;h3 id='my_site_at_dreamhost__'&gt;My site at Dreamhost - &lt;code&gt;go.pjs.name&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;I also have a site at Dreamhost - &lt;code&gt;go.pjs.name&lt;/code&gt;. It serves me as a place where I can share data with my friends. I just upload some data, create a unique link (e.g. http://go.pjs.name/d/9f166080-2fe1-4600-92bb-d42dc19c453b/) and voila. I could, of course, use a specialized service, e.g. &lt;a href='http://db.tt/2450WkK'&gt;Dropbox&lt;/a&gt; or do some other nifty things like setting up a username and password or maybe even SSL. But still - there are situations that this level of security is all I need.&lt;/p&gt;

&lt;p&gt;There is a problem with how you set up the DNS records. The straightforward approach would be to get the current host at Dreamhost that keeps your data, get its IP address and create an &lt;code&gt;A&lt;/code&gt; records pointing to that IP address. This is not a bulletproof solution, unfortunately. If the IP addresses at Dreamhost changes, you end up with an unreachable site.&lt;/p&gt;

&lt;h3 id='solution'&gt;Solution&lt;/h3&gt;

&lt;p&gt;The solution is very simple. All you need to do is to create &lt;code&gt;NS&lt;/code&gt; records for the site/domain you wish to host at Dreamhost and point it to the Dreamhost&amp;#8217;s DNS servers. So, in our example, this would look like the following:&lt;/p&gt;
&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='nv'&gt;$ &lt;/span&gt;dig -t ns go.pjs.name @ns1.onoclea.net

;; QUESTION SECTION:
;go.pjs.name.                   IN      NS

;; AUTHORITY SECTION:
go.pjs.name.            86400   IN      NS      ns2.dreamhost.com.
go.pjs.name.            86400   IN      NS      ns3.dreamhost.com.
go.pjs.name.            86400   IN      NS      ns1.dreamhost.com.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And that&amp;#8217;s it. Now you don&amp;#8217;t have to worry that your site becomes unreachable because somebody decides to change an IP address somewhere at Dreamhost. Notifying all the customers that could be potentially affected is almost impossible, so don&amp;#8217;t expect it. What you can do instead is to rely on the fact that the DNS data must be kept valid. And this is one way of doing that :)&lt;/p&gt;

&lt;h2 id='conclusions'&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;DNS is not limited just to &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;MX&lt;/code&gt; and &lt;code&gt;CNAME&lt;/code&gt; records&amp;#8230; and this one tiny feature of it just made my life a bit easier :)&lt;/p&gt;</content>
	</entry>
	
	<entry>
		<title>Nginx and Amazon S3 CDN</title>
		<link href="http://en.onoclea.com/bits/nginx-and-amazon-s3-cdn.html"/>
		<updated>2011-01-12T00:00:00+01:00</updated>
		<id>http://en.onoclea.com/bits/nginx-and-amazon-s3-cdn</id>
		<content type="html">&lt;p&gt;One of the projects I&amp;#8217;ve been working on recently required a reliable CDN. There were a number of requirements that the desing had to follow. One of the limitations was the price tag, so going with something like Akamai or Limelight was not an option. This had to be a more or less in-house solution and I was given a task to prepare it.&lt;/p&gt;

&lt;h2 id='requirements'&gt;Requirements&lt;/h2&gt;

&lt;p&gt;There were a few requirements the project had to meet.&lt;/p&gt;

&lt;h3 id='reliability'&gt;Reliability&lt;/h3&gt;

&lt;p&gt;First and foremost - this had to be a proven technology. Or at least something that would make me (i.e. the system administrator&amp;#8217;s) sleep safe and sound :)&lt;/p&gt;

&lt;h3 id='two_types_of_content__public_and_private'&gt;Two types of content - public and private&lt;/h3&gt;

&lt;p&gt;The CDN had to serve two types of content. One was public, that any user could access. The other had to be protected and should be served only for authorized users.&lt;/p&gt;

&lt;h3 id='ssl_distribution_of_the_private_content'&gt;SSL distribution of the private content&lt;/h3&gt;

&lt;p&gt;Both the private and public content had to be served over a secure connection. There was no limitation on whether the certificate had to be signed by a recognised authority. Self-signed certificates were &amp;#8220;just fine&amp;#8221;.&lt;/p&gt;

&lt;h2 id='the_solution'&gt;The solution&lt;/h2&gt;

&lt;p&gt;Given the above requirements I came up with a solution that was basing on the following two components:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Amazon EC2 AMI with an nginx server acting as a forward-proxy&lt;/li&gt;

&lt;li&gt;Amazon S3 used as the backend storage for both the private and public content&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since the application, that was going to make use of the CDN, was not an ordinary web browser, we could make it work without the HTTP load balancer. Instead, a DNS round-robin was used. This approach eliminated a layer of load balancers that not only cost money to run, but also create an area where something may go wrong.&lt;/p&gt;

&lt;h2 id='usecase_scenarios'&gt;Use-case scenarios&lt;/h2&gt;

&lt;p&gt;There are two use case scenarios.&lt;/p&gt;

&lt;h3 id='public_access'&gt;Public access&lt;/h3&gt;

&lt;p&gt;The public access model allows the user to access files directly from Amazon S3.&lt;/p&gt;

&lt;p&gt;&lt;img alt='Public access path' src='http://static.onoclea.com/images/bits/nginx-and-amazon-s3-cdn/cdn-public_access.png' /&gt;&lt;/p&gt;

&lt;p&gt;No middleman is necessary as the traffic may go directly to Amazon S3 servers.&lt;/p&gt;

&lt;h3 id='private_access'&gt;Private access&lt;/h3&gt;

&lt;p&gt;The private content is proxied (with the help of &lt;code&gt;X-Accel-Redirect&lt;/code&gt; (see this article: &lt;a href='http://kovyrin.net/2010/07/24/nginx-fu-x-accel-redirect-remote/'&gt;Nginx-Fu: X-Accel-Redirect From Remote Servers&lt;/a&gt;) and the &lt;a href='http://wiki.nginx.org/XSendfile'&gt;&lt;code&gt;XSendFile&lt;/code&gt; nginx module&lt;/a&gt;) by nginx, with the original version stored safely on Amazon S3.&lt;/p&gt;

&lt;p&gt;&lt;img alt='Private access path' src='http://static.onoclea.com/images/bits/nginx-and-amazon-s3-cdn/cdn-private_access.png' /&gt;&lt;/p&gt;

&lt;p&gt;This way we can have many &lt;code&gt;api&lt;/code&gt; machines without the trouble of having to keep them synchronized. The most up-to-date content is always available from Amazon S3. No extra costs for the EBS storage or complex DRBD setups.&lt;/p&gt;

&lt;h3 id='amazon_s3'&gt;Amazon S3&lt;/h3&gt;

&lt;p&gt;OK, so here goes the fun and technical part.&lt;/p&gt;

&lt;h4 id='bucket_policy'&gt;Bucket policy&lt;/h4&gt;

&lt;p&gt;Firstly - we must set an appropriate Amazon S3 bucket policy. The one I used looked more or less like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
 &amp;quot;Statement&amp;quot;: [
  {
   &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
   &amp;quot;Principal&amp;quot;: {
    &amp;quot;AWS&amp;quot;: &amp;quot;*&amp;quot; 
   },
   &amp;quot;Action&amp;quot;: &amp;quot;s3:GetObject&amp;quot;,
   &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:s3:::myproject/public/*&amp;quot; 
  },
  {
   &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
   &amp;quot;Principal&amp;quot;: {
    &amp;quot;AWS&amp;quot;: &amp;quot;*&amp;quot; 
   },
   &amp;quot;Action&amp;quot;: &amp;quot;s3:*&amp;quot;,
   &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:s3:::myproject/private/*&amp;quot;,
   &amp;quot;Condition&amp;quot;: {
    &amp;quot;IpAddress&amp;quot;: {
     &amp;quot;aws:SourceIp&amp;quot;: [
      &amp;quot;api_0_ip_address/32&amp;quot;,
      &amp;quot;api_1_ip_address/32&amp;quot; 
     ]
    }
   }
  }
 ]
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There was a single bucket called &lt;code&gt;myproject&lt;/code&gt; with two folders - &lt;code&gt;private&lt;/code&gt; and &lt;code&gt;public&lt;/code&gt;. The latter is widely available. The former, on the other hand, can be accessed only from the machines, whose IP addresses were explicitly set in the policy conditions.&lt;/p&gt;

&lt;h4 id='upload_user_iam_policy'&gt;Upload user IAM policy&lt;/h4&gt;

&lt;p&gt;This, on the other hand, is the IAM policy for a maintenance user. When attached to a user (say&amp;#8230; &amp;#8220;myproject-cdn-maintainer&amp;#8221;) it will restrict its operation to uploading/modifying content and prevent any ACL/policy operations, that could leave the system in a inoperable state.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;Statement&amp;quot;: [
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: [
        &amp;quot;s3:GetObject&amp;quot;,
        &amp;quot;s3:PutObject&amp;quot;,
        &amp;quot;s3:GetObjectAcl&amp;quot;,
        &amp;quot;s3:PutObjectAcl&amp;quot;,
        &amp;quot;s3:DeleteObject&amp;quot; 
      ],
      &amp;quot;Resource&amp;quot;: [
        &amp;quot;arn:aws:s3:::myproject/private/*&amp;quot;,
        &amp;quot;arn:aws:s3:::myproject/public/*&amp;quot; 
      ]
    },
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: &amp;quot;s3:ListAllMyBuckets&amp;quot;,
      &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:s3:::*&amp;quot; 
    },
    {
      &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;,
      &amp;quot;Action&amp;quot;: &amp;quot;s3:ListBucket&amp;quot;,
      &amp;quot;Resource&amp;quot;: &amp;quot;arn:aws:s3:::myproject&amp;quot; 
    }
  ]
}&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id='nginx_configuration'&gt;Nginx configuration&lt;/h4&gt;

&lt;p&gt;The nginx configuration (the relevan part) looked the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;location ~* ^/private/(.*) {
 internal;

 resolver 172.16.0.23;

 set $download_uri $1;
 set $download_host myproject.s3.amazonaws.com;
 set $download_prefix private;

 proxy_set_header Authorization &amp;#39;&amp;#39;;
 proxy_set_header Host $download_host;

 proxy_hide_header X-Amz-Id-2;
 proxy_hide_header X-Amz-Request-Id;
 proxy_hide_header ETag;
 proxy_hide_header Last-Modified;

 set $download_url http://$download_host/$download_prefix/$download_uri;

 error_log /var/log/nginx/api.myproject.onoclea.net_private-error.log debug;
 access_log /var/log/nginx/api.myproject.onoclea.net_private-access.log main;

 # retry on Amazon errors
 proxy_next_upstream error timeout http_500 http_502 http_503 http_504;

 # pass only GETs
 proxy_method GET;
 proxy_pass_request_body off;
 proxy_set_header Content-Length &amp;#39;&amp;#39;;

 # disable buffering
 proxy_buffering off;
 proxy_max_temp_file_size 0;

 proxy_pass $download_url;
}&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The idea is that whenever the backend application (the one that is going to verify if a user can get an access to the private content) responds with an appropriate &lt;code&gt;X-Accel-Redirect&lt;/code&gt; header, the internal location will serve a protected content from the Amazon S3. Since the traffic between S3 and EC2 is charged $0 per GiB (i.e. it&amp;#8217;s free) this imposes no additional costs.&lt;/p&gt;

&lt;h2 id='caveats'&gt;Caveats&lt;/h2&gt;

&lt;p&gt;There were some minor quirks I came across.&lt;/p&gt;

&lt;h3 id='pay_attention_to_default_permissions_while_uploading_your_data'&gt;Pay attention to default permissions while uploading your data&lt;/h3&gt;

&lt;p&gt;First of all - remove all ACLs from the data uploaded to S3. According to the IAM (AWS Identity and Access Management) documentation (&lt;a href='http://docs.amazonwebservices.com/IAM/latest/UserGuide/index.html?AccessPolicyLanguage_EvaluationLogic.html'&gt;IAM Access Policy Language Evaluation Logic&lt;/a&gt;) object ACLs will override general allow/deny policies. Since &lt;a href='http://cyberduck.ch/'&gt;Cyberduck&lt;/a&gt;, a tool I used to upload the test content, sets a default &amp;#8216;read all&amp;#8217; ACL (&lt;a href='http://trac.cyberduck.ch/wiki/help/en/howto/s3#DefaultACLs'&gt;see the doc&lt;/a&gt;) I had to spent some time figuring why the content that should be kept private is widely available. Purging all ACLs fixed that.&lt;/p&gt;

&lt;h3 id='if_you_want_https_access_you_cannot_use_cnames'&gt;If you want https access you cannot use CNAMEs&lt;/h3&gt;

&lt;p&gt;The wildcard certificate, issued for the S3 service, is valid only for &lt;code&gt;*.s3.amazonaws.com&lt;/code&gt;. So if you want to get your CNAME point to the S3 you will get security warning if you use https. So etiher stay with the plain HTTP (i.e. http://cdn.myproject.com) or use a single-level subdomain (http://cdn-myproject-com.s3.amazon.aws.com).&lt;/p&gt;</content>
	</entry>
	
	<entry>
		<title>Soft-drink vending machine high level design</title>
		<link href="http://en.onoclea.com/bits/soft-drink-vending-machine-high-level-design.html"/>
		<updated>2010-11-23T00:00:00+01:00</updated>
		<id>http://en.onoclea.com/bits/soft-drink-vending-machine-high-level-design</id>
		<content type="html">&lt;p&gt;During one of my job interviews I was asked to present a high level design of a soft-drink vending machine. So I sat down and tried to think what would the perfect soft-drink machine look like. This is the version I came up with. The task itself was limited to 30 minutes, so this is not a full-fledged design.&lt;/p&gt;

&lt;h2 id='general_design'&gt;General design&lt;/h2&gt;

&lt;p&gt;A typical soft-drink vending machine is built as a standalone and a self-contained, tamper-proof device, connected physically only to a power outlet. The machine’s sole purpose is to issue/release a soft-drink to end-users in exchange for a cleared payment procedure. The machine should communicate with the operations centre and transfer (via e.g. a wireless link) a set of status information, such as the number and kind of goods left, any problems it observed (power outage, cash box overfill, mechanical jams) or the fact that the doors were opened, which could either mean that the technician arrived to resupply the unit (which is good) or that somebody tried to steal from it. The main components include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;a storage area with a set of sensors (infrared or weight based), used to count the number of goods left&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;battery used to sustain the unit’s operation during power outage&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;money accepting and verification unit; depending on requirements it can either accept coins, cash, credit cards, RFID tags or any other kind of token, such as magnetic keys or proximity cards&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;a user interface unit used to interact with the machine; it can range from a simple keyboard, without any display up to a hi-res touchscreen display with a set of stereo speakers that can, during standby, serve as a advertisement&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;a gyroscope, an accelerometer and a GPS unit used to locate the machine and report any misbehavior (changing the position of the device in order to get to the goods locked inside).&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;a two way wireless link (e.g. a GPRS modem) used for a bi-directional communications with the operations centre&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;an internal storage used to keep operation logs or usage statistics used for offline billing and reporting (e.g a flash card or a tape drive).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id='main_use_cases_explaining_the_functionality'&gt;Main use cases explaining the functionality&lt;/h2&gt;

&lt;p&gt;The list of most commonly met use-case scenarios.&lt;/p&gt;

&lt;h3 id='normal_idle_operation'&gt;Normal (idle) operation&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Machine displays (if it is capable of) a welcome message and waits for the user to start the operation - choose a drink to be sold.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;It periodically reports its current status (a keep-alive message) including e.g. current stock levels, environmental conditions, its geographical position etc.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id='resupplying_with_afresh_batch_of_drinks'&gt;Resupplying with a fresh batch of drinks&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;A worker arrives at the machine.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Machine is put into service mode.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Doors are opened.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Supplies are refilled.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Doors are closed.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Machine is set to normal mode.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Before going on-line, machine performs a set of checks, notes the current number of supplies and reports its current status to the operations centre together with the fact that it went a resupply operation.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Before leaving the site, worker tests the operation by going through a regular process of buying a drink.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id='working_under_apower_failure_situation'&gt;Working under a power failure situation&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The machine continues to operate as usual until the energy levels drop to a certain value - e.g. 20%.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;After reaching the “service charge” level (20%), the machine goes into service mode. It does not sell any drinks. However, it still reports its status to the operations center, including the battery level.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Once the batteries are almost discharged, the machine shuts down. It locks itself down, preventing unauthorized access.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;When the power is restored, the machine starts up and performs a set of self-tests.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;If the tests are completed without errors, the machine goes into normal/idle mode.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;If any of the tests fails, the machine continues to operate in the service mode and notifies the operations centre about its condition - presumably causing a technician to arrive.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id='abnormal_operation'&gt;Abnormal operation&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If any abnormal conditions are observed, the machine goes into service mode.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;A status message is sent to the operations centre.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;The operations centre may either remotely shut down/lock the machine, force a restart or give “a green light” and restore its normal operations.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Machine periodically performs a set of self-tests. If the tests complete without errors, a normal mode is restore.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Description of a process of buying a drink&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id='user_chooses_adrink'&gt;User chooses a drink.&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If the drink is not available an appropriate message is displayed.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;If the drink is available, a required amount of money is displayed.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;User inserts coins/notes/cards or any other token (a magnetic key, an RFID tag etc.)&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;A payment verification takes place. Depending on the payment method the process may include checking if the coins are of correct size, weight, if they interact with magnetic waves. If a banknote is inserted, it may be additionally checked using UV light. Other means of payment, like credit/debit cards, RFID tags or magnetic keys, require connecting to a central database in order to clear the transaction or alternatively - locally store the transaction information for a future, offline billing.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Once the payment is cleared, the drink is released.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;The stocks are recalculated.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;The transaction status is sent to the operations center either after each operation, in batches (e.g. after 10 operations) or after a certain time elapsed (every 10 minutes) - depending on the required granularity.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</content>
	</entry>
	
	<entry>
		<title>Postifx + Dovecot Deliver + Catchall Addresses - Impossible is nothing!</title>
		<link href="http://en.onoclea.com/bits/postfix-devecot-deliver-catchall.html"/>
		<updated>2008-02-11T00:00:00+01:00</updated>
		<id>http://en.onoclea.com/bits/postfix-devecot-deliver-catchall</id>
		<content type="html">&lt;p&gt;For over a year now I&amp;#8217;ve been struggling with something I thought would never get solved. Though the setup I have (postfix + dovecot) isn&amp;#8217;t really complicated, it does have some nifty features. Among many of them is the fact that I use catchall addresses in most of my domains. On the top of that I wanted to use Sieve to filter some of my mail on the server side (especially those &amp;#8220;you always read them&amp;#8221; daily log reports).&lt;/p&gt;

&lt;p&gt;But there was a problem. I&amp;#8217;ve even made a post on the Dovecot mailinglist:&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.dovecot.org/list/dovecot/2006-March/012064.html'&gt;http://www.dovecot.org/list/dovecot/2006-March/012064.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In general - dovecot cannot mimic postfix&amp;#8217; way of handling catch-all addresses - there was nothing even similar to the &amp;#8220;table search order&amp;#8221; found in my favorite MTA. So I made a rather ugly patch&amp;#8230; and it worked. But it was such a dirty hack that merging it with the dovecot&amp;#8217;s trunk wasn&amp;#8217;t really an option. So whenever a new dovecot release was published I had to manually prepare my &amp;#8220;own&amp;#8221; version. So I ended up having two separate setups depending on the client&amp;#8217;s demands - either a vanilla dovecot without my patch (that was updated on a regular basis) or a hacked version that&amp;#8230; well&amp;#8230; should be updated :)&lt;/p&gt;

&lt;p&gt;Couple of days ago I was contacted by Maciej Paczesny asking if there was any progress with the problem I reported back in 2006.&lt;/p&gt;

&lt;p&gt;After exchanging some emails and thoughts I think I&amp;#8217;ve finally found a neat way of getting &amp;#8220;things done right&amp;#8221;.&lt;/p&gt;

&lt;p&gt;&lt;a href='http://www.postfix.org/canonical.5.html'&gt;http://www.postfix.org/canonical.5.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;All you have to do in fact is to rewrite the recipient address using postfix&amp;#8217; recipient_canonical_maps table. That&amp;#8217;s all. Thanks to this little trick, dovecot-deliver receives an address that is final and unique so it doesn&amp;#8217;t have any troubles locating a proper message store directory.&lt;/p&gt;

&lt;p&gt;Technically speaking, you must define recipient_canonical_maps in such a way that it would return final and unique address for any of your users (here we can benefit from postfix&amp;#8217; table search order, so catch-all addresses do work!). Then postfix will rewrite the envelope &amp;#8220;To:&amp;#8221; header, pass it to dovecot and voila - problem solved.&lt;/p&gt;

&lt;p&gt;Thanks Maciej! :)&lt;/p&gt;</content>
	</entry>
	
	<entry>
		<title>Why I adore HP ProCurve switches</title>
		<link href="http://en.onoclea.com/bits/why-I-adore-hp-procurve-switches.html"/>
		<updated>2007-01-06T00:00:00+01:00</updated>
		<id>http://en.onoclea.com/bits/why-I-adore-hp-procurve-switches</id>
		<content type="html">&lt;p&gt;You may say that the subject is over-exaggerated. I do, however, claim that thanks to this fine piece of &amp;#8220;automation&amp;#8221; I have saved myself loads of time. Instead of logging onto a one server at a time, I could easily create automated tasks without a overpriced and GUI only tools.&lt;/p&gt;

&lt;p&gt;&lt;div class='highlight'&gt;&lt;pre&gt;&lt;code class='bash'&gt;&lt;span class='o'&gt;[&lt;/span&gt;user@host ~&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='nv'&gt;$ &lt;/span&gt;cat download/update
&lt;span class='nb'&gt;cd &lt;/span&gt;os
put H_08_106.swi secondary
&lt;span class='o'&gt;[&lt;/span&gt;user@host ~&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='nv'&gt;$ &lt;/span&gt;&lt;span class='nb'&gt;eval&lt;/span&gt; &lt;span class='sb'&gt;`&lt;/span&gt;ssh-agent&lt;span class='sb'&gt;`&lt;/span&gt;
Agent pid 25066
&lt;span class='o'&gt;[&lt;/span&gt;user@host ~&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='nv'&gt;$ &lt;/span&gt;ssh-add id_dsa
Enter passphrase &lt;span class='k'&gt;for &lt;/span&gt;id_dsa:
Identity added: id_dsa &lt;span class='o'&gt;(&lt;/span&gt;id_dsa&lt;span class='o'&gt;)&lt;/span&gt;
&lt;span class='o'&gt;[&lt;/span&gt;user@host ~&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='nv'&gt;$ &lt;/span&gt;&lt;span class='nb'&gt;cd &lt;/span&gt;download; sftp -b update host
sftp&amp;gt; &lt;span class='nb'&gt;cd &lt;/span&gt;os
sftp&amp;gt; put H_08_106.swi secondary
Uploading H_08_106.swi to /os/secondary
Connection to host closed by remote host.
&lt;span class='o'&gt;[&lt;/span&gt;user@host download&lt;span class='o'&gt;]&lt;/span&gt;&lt;span class='err'&gt;$&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;And that&amp;#8217;s it - the switch is upgraded!&lt;/p&gt;</content>
	</entry>
	
</feed>
